{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c36c6c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn import metrics\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import functools\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tempfile\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, balanced_accuracy_score\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.parsing import preprocessing\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from torchmetrics import AveragePrecision\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc3b9dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.1+cu111'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d42351f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿CUDA disponible? True\n"
     ]
    }
   ],
   "source": [
    "print(f\"¿CUDA disponible? {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acece3d9",
   "metadata": {},
   "source": [
    "## Exploración de datos\n",
    "Cargamos los datos de entrenamiento para ver que forma tienen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a2f272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = pd.read_json('./data/meli-challenge-2019/spanish.train.jsonl.gz',lines=True)\n",
    "# train_dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3106307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c98af1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.label_quality.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbc03df",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Tomado de https://github.com/DiploDatos/AprendizajeProfundo/blob/master/3_datasets.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "428e51ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeLiChallengeDataset(IterableDataset):\n",
    "    def __init__(self, path, transform=None, key = 'title'):\n",
    "        \"\"\"\n",
    "        path: Ubicación a los datos (comprimidos con gzip)\n",
    "        key: Columna que vamos a usar para entrenar\n",
    "        \"\"\"\n",
    "        self.dataset_path = path\n",
    "        self.transform = transform\n",
    "        self.key = key\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Habilita un iterador sobre los datos\n",
    "        \"\"\"\n",
    "        with gzip.open(self.dataset_path, \"rt\") as fh:\n",
    "            for l in fh:\n",
    "                data = json.loads(l)\n",
    "                item = {\n",
    "                    \"data\": data[self.key],\n",
    "                    \"target\": data['target']\n",
    "                }\n",
    "                \n",
    "                if self.transform:\n",
    "                    yield self.transform(item)\n",
    "                else:\n",
    "                    yield item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bd1d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadSequences:\n",
    "    def __init__(self, pad_value=0, max_length=None, min_length=1):\n",
    "        assert max_length is None or min_length <= max_length\n",
    "        self.pad_value = pad_value\n",
    "        self.max_length = max_length\n",
    "        self.min_length = min_length\n",
    "\n",
    "    def __call__(self, items):\n",
    "        data, target = list(zip(*[(item[\"data\"], item[\"target\"]) for item in items]))\n",
    "        seq_lengths = [len(d) for d in data]\n",
    "        \n",
    "\n",
    "        if self.max_length:\n",
    "            max_length = self.max_length\n",
    "            seq_lengths = [min(self.max_length, l) for l in seq_lengths]\n",
    "        else:\n",
    "            max_length = max(self.min_length, max(seq_lengths))\n",
    "\n",
    "        data = [d[:l] + [self.pad_value] * (max_length - l)\n",
    "                for d, l in zip(data, seq_lengths)]\n",
    "            \n",
    "        return {\n",
    "#            \"data\": torch.LongTensor(data),\n",
    "            \"data\": torch.FloatTensor(data), \n",
    "            \"target\": torch.FloatTensor(target)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2ce9866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una collate_fn que nos retorne todos los arreglos de la misma longitud\n",
    "# data_len = train_dataset.data.apply(lambda v: len(v))\n",
    "# max_len = data_len.max()\n",
    "\n",
    "pad_to_len = PadSequences(max_length=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502e15a3",
   "metadata": {},
   "source": [
    "### Juntando todo\n",
    "Tenemos\n",
    "* Una clase con la responsabilidad de entregar datos, potencialmente preprocesandolos si hace falta\n",
    "* Una función que transforma los datos leidos para que todos los valores tengan la misma longitud\n",
    "\n",
    "A partir de esto, creamos dos instancia del `DataLoader`: Uno para cargar los datos de entrenamiento y otro para cargar los datos de _test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16108441",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MeLiChallengeDataset('./data/meli-challenge-2019/spanish.train.jsonl.gz', key = 'data')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=False, num_workers=0, collate_fn = pad_to_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52d91f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MeLiChallengeDataset('./data/meli-challenge-2019/spanish.validation.jsonl.gz', key = 'data') \n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=0, collate_fn = pad_to_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc4460",
   "metadata": {},
   "source": [
    "## MLP\n",
    "\n",
    "Tomamos el MLP de las clases y agregamos los parametros que nos interesan\n",
    "\n",
    "* Capa de entrada: Tantas neuronas como tokens\n",
    "* Capa de salida: Tantas neuronas como categorías (632)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0140e662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden = []):\n",
    "        \"\"\"\n",
    "        input_size: Número de neuronas de entrada\n",
    "        output_size: Número de neuronas de salida\n",
    "        hidden: Lista con los numeros de capas ocultas\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        assert len(hidden) > 0\n",
    "        \n",
    "        self._name = str(input_size) +'_'+ \"_\".join(map(lambda i: str(i), hidden)) + '_' + str(output_size)\n",
    "        \n",
    "        neurons = [input_size]  + hidden \n",
    "        parts = []\n",
    "        for idx, each in enumerate(neurons[:-1]):\n",
    "            parts.append(nn.Linear(each, neurons[idx + 1]))\n",
    "            parts.append(nn.ReLU())\n",
    "            \n",
    "        parts = parts + [nn.Linear(neurons[-1], 1), nn.Sigmoid()]\n",
    "        \n",
    "        self.model = nn.Sequential(*parts)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def name(self):\n",
    "        return \"MLP_\" + self._name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a03b08c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MLP_10_16_2'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP(10, 2 , hidden = [16]).name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c21682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d466303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.set_experiment(\"MLP Basico\")\n",
    "\n",
    "# with mlflow.start_run():\n",
    "#     mlflow.log_param(\"model_name\", \"mlp\") # TODO Log parameters\n",
    "#     mlflow.log_param(\"epochs\", \"1\")\n",
    "#     mlflow.log_param(\"hidden_layer_1_neurons\", \"2\")\n",
    "    \n",
    "#     model = MLP(20, 632, hidden= [2]) # 20 -> 2 -> 632\n",
    "#     loss = nn.BCELoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    \n",
    "# #     model.to(device)\n",
    "#     for epoch in trange(1): # TODO Pruebas con varias epochs\n",
    "#         model.train()\n",
    "#         running_loss = []\n",
    "#         for idx, batch in enumerate(tqdm(train_dataloader)):\n",
    "#             optimizer.zero_grad()\n",
    "            \n",
    "# #             input_data = batch[\"data\"].to(device)\n",
    "#             input_data = batch[\"data\"]\n",
    "# #             output = model(batch[\"data\"])\n",
    "#             output = model(input_data)\n",
    "    \n",
    "# #             target_data = batch[\"target\"].view(-1,1).to(device)\n",
    "#             target_data = batch[\"target\"].view(-1,1)\n",
    "#             loss_value = loss(output, target_data)\n",
    "#             loss_value.backward()\n",
    "#             optimizer.step()\n",
    "#             running_loss.append(loss_value.item())        \n",
    "#         mlflow.log_metric(\"train_loss\", sum(running_loss) / len(running_loss), epoch)\n",
    "        \n",
    "#         model.eval()\n",
    "#         running_loss = []\n",
    "#         targets = []\n",
    "#         predictions = []\n",
    "#         for batch in tqdm(test_dataloader):\n",
    "#             output = model(batch[\"data\"])\n",
    "#             running_loss.append(\n",
    "#                 loss(output, batch[\"target\"].view(-1, 1)).item()\n",
    "#             )\n",
    "#             targets.extend(batch[\"target\"].numpy())\n",
    "#             predictions.extend(output.squeeze().detach().numpy())\n",
    "#         mlflow.log_metric(\"test_loss\", sum(running_loss) / len(running_loss), epoch)\n",
    "#         # Reemplazamos la siguiente metrica por la de pythorch (La de scikit learn no acepta problemas multiclase)\n",
    "\n",
    "#         mlflow.log_metric(\"test_avp\", balanced_accuracy_score(targets, predictions), epoch)        \n",
    "\n",
    "#     with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "#             targets = []\n",
    "#             predictions = []\n",
    "#             for batch in tqdm(test_dataloader):\n",
    "#                 output = model(batch[\"data\"])\n",
    "#                 targets.extend(batch[\"target\"].numpy())\n",
    "#                 predictions.extend(output.squeeze().detach().numpy())\n",
    "#             pd.DataFrame({\"prediction\": predictions, \"target\": targets}).to_csv(\n",
    "#                 f\"{tmpdirname}/predictions.csv.gz\", index=False\n",
    "#             )\n",
    "#             mlflow.log_artifact(f\"{tmpdirname}/predictions.csv.gz\")\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe899a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_train_dataloader = lambda bs: DataLoader(train_dataset, batch_size=bs, shuffle=False, num_workers=0, collate_fn = pad_to_len)\n",
    "get_test_dataloader = lambda bs: DataLoader(test_dataset, batch_size=bs, shuffle=False, num_workers=0, collate_fn = pad_to_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4be2296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(params, **kwargs):\n",
    "    \"\"\"\n",
    "    Run a single experiment\n",
    "\n",
    "    params: A list of (model, loss_fn, optimizer,num_epochs) tuples\n",
    "    \"\"\"\n",
    "    for(build_model, build_loss, build_optimizer, nepochs, batch_sizes) in params:\n",
    "\n",
    "        # Pasamos varios valores para epochs, ejecutamos un experimento para cada uno\n",
    "        for epochs in nepochs:\n",
    "            for bs in batch_sizes:\n",
    "                \n",
    "                print(f\"Experiment epochs:{epochs}, batch-size:{bs}\")\n",
    "                train_dataloader = get_train_dataloader(bs)\n",
    "                test_dataloader = get_test_dataloader(bs)\n",
    "                \n",
    "                with mlflow.start_run():\n",
    "                    # Crea nuevos objetos para cada epoca\n",
    "                    model = build_model()\n",
    "                    optimizer = build_optimizer(model)\n",
    "                    loss = build_loss()\n",
    "\n",
    "                    exp_name = model.name() + \"_e\" + str(epochs) + \"_b\" + str(bs)\n",
    "                    mlflow.set_experiment(exp_name)\n",
    "\n",
    "                    mlflow.log_param(\"model_name\", model.name())\n",
    "                    mlflow.log_param(\"epochs\", str(epochs))\n",
    "                    mlflow.log_param(\"batch_size\", str(bs))\n",
    "\n",
    "                    model#.to(device)\n",
    "                    for epoch in trange(epochs):\n",
    "\n",
    "                        model.train()\n",
    "                        running_loss = []\n",
    "                        for idx, batch in enumerate(tqdm(train_dataloader)):\n",
    "                            optimizer.zero_grad()\n",
    "\n",
    "                            input_data = batch[\"data\"]#.to(device)\n",
    "                            output = model(input_data)\n",
    "\n",
    "                            target_data = batch[\"target\"].view(-1,1)#.to(device)\n",
    "                            loss_value = loss(output, target_data)\n",
    "                            loss_value.backward()\n",
    "\n",
    "                            optimizer.step()\n",
    "                            running_loss.append(loss_value.item())\n",
    "                        mlflow.log_metric(\"train_loss\", sum(running_loss) / len(running_loss), epoch)\n",
    "\n",
    "                        model.eval()\n",
    "                        running_loss = []\n",
    "                        targets = []\n",
    "                        predictions = []\n",
    "                        for batch in tqdm(test_dataloader):\n",
    "                            output = model(batch[\"data\"])\n",
    "                            running_loss.append(\n",
    "                                loss(output, batch[\"target\"].view(-1, 1)).item()\n",
    "                            )\n",
    "                            targets.extend(batch[\"target\"].numpy())\n",
    "                            predictions.extend(output.squeeze().detach().numpy())\n",
    "\n",
    "                        mlflow.log_metric(\"test_loss\", sum(running_loss) / len(running_loss), epoch)\n",
    "                        mlflow.log_metric(\"test_avp\", balanced_accuracy_score(targets, predictions), epoch)\n",
    "\n",
    "                  #\n",
    "                  #\n",
    "                    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "                        targets = []\n",
    "                        predictions = []\n",
    "\n",
    "                        for batch in tqdm(test_dataloader):\n",
    "                            output = model(batch[\"data\"])\n",
    "                            targets.extend(batch[\"target\"].numpy())\n",
    "                            predictions.extend(output.squeeze().detach().numpy())\n",
    "\n",
    "                        filename = \"{}/{}_predictions.csv.gz\".format(tmpdirname, exp_name)\n",
    "                        pd.DataFrame({\"prediction\": predictions, \"target\": targets}).to_csv(\n",
    "                            filename, index=False\n",
    "                        )\n",
    "                        mlflow.log_artifact(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca1c1896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/18 22:27:04 INFO mlflow.tracking.fluent: Experiment with name 'MLP_20_256_632_e1_b24' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment epochs:1, batch-size:24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0267dea1926444159c0f82e6676a8c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a27f99a032481883e6943805f78262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8095b05a0149199aa21796115466ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bda4ac9b2804e15bf7eb5c5c9b4d50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/18 22:36:44 INFO mlflow.tracking.fluent: Experiment with name 'MLP_20_256_632_e1_b48' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment epochs:1, batch-size:48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c985fd763e4d2ca5d913d2acf32a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3932c0b1dd4315931204b88e04bd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a0e548b9144ec3a79e931b31e56640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b55083faa641f2b5386a5445685cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/18 22:42:55 INFO mlflow.tracking.fluent: Experiment with name 'MLP_20_256_632_e1_b64' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment epochs:1, batch-size:64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457f94933d2d4f42acc3bd1de60f85ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2158512050fd410db8fb01e9a10e431c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966213b60cd1482d930debf38516719b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546d29c019fb41549cb2dbcc4e5037fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/18 22:48:03 INFO mlflow.tracking.fluent: Experiment with name 'MLP_20_256_632_e2_b24' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment epochs:2, batch-size:24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d45eabf769461a95e7b7c3662fa45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b5299faf2f4f8e83211e5b67a15268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cfe7d30b4434a3cb68d6f75460efb5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70622f41f3184b529bd3b59198d04185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0f4683645140f0932d44e4c81c1a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913fa3bd73e14b05a38ad3091243d890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/18 23:05:45 INFO mlflow.tracking.fluent: Experiment with name 'MLP_20_256_632_e2_b48' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment epochs:2, batch-size:48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a503f7d6d3ef4ae9aad046f4a425b3f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03eb1784b1d84c6a842fbe2f95c62e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0232a054dc924654947af20c5cd59a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3467358/2809433109.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmlp_multiple_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m632\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp_single_layer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmlp_multiple_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_3467358/4045751371.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(params, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                         \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                         \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_avp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbalanced_accuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                   \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mbalanced_accuracy_score\u001b[0;34m(y_true, y_pred, sample_weight, adjusted)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[0;36m0.625\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m     \"\"\"\n\u001b[0;32m-> 1995\u001b[0;31m     \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \u001b[0mper_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "loss = lambda : nn.BCELoss()\n",
    "\n",
    "def getOptimizer(model, lr = 1e-3, wd = 1e-5):\n",
    "    return optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "\n",
    "                   \n",
    "epochs = [1, 2, 4]\n",
    "batch_sizes = [24, 48, 64]\n",
    "\n",
    "\n",
    "mlp_single_layer = [(lambda : MLP(20, 632, hidden = [256]), loss, getOptimizer, epochs, batch_sizes)]\n",
    "mlp_multiple_layers = [(lambda : MLP(20, 632, hidden = [40,64,256, 512]), loss, getOptimizer, epochs, batch_sizes)]\n",
    "\n",
    "run_experiment(mlp_single_layer + mlp_multiple_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f69b298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
